{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAL Labo 1d : Segmenting Texts in Foreign Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this complement to Labs 1b and 1c is to process texts in other languages than English.\n",
    "\n",
    "First of all, we will look at how to process encodings correctly.  Then we will try several sentence segmenters and tokenizers from NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested data\n",
    "http://www.gutenberg.org/files/19040/19040-8.txt : book in Hungarian, ISO-8859-2 (latin2) encoding\n",
    "\n",
    "http://www.gutenberg.org/files/41211/41211-8.txt : book in French, ISO-8859-1 (latin1) encoding\n",
    "\n",
    "http://www.gutenberg.org/files/28049/28049-0.txt : book in Polish, UTF-8 encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What are the declared encodings of each file?*\n",
    "Je ne comprends pas vraiment votre question étant donné que vous nous écrivez l'encodage de chaque texte juste à côté\n",
    "mais je vais quand même essayer d'apporter quelques précisions. Au début de chaque texte(dans l'en-tête), il y a l'information\n",
    "après ce texte : \"Character set encoding:\". Si on essaye de voir dans un navigateur on peut aussi avoir certaines informations\n",
    "dans le menu(sous affichage -> encodage du texte), en l'occurrence \"Occidentale\" pour nos trois textes. Sinon il n'y a théoriquement pas de moyens pour la machine de savoir quel encodage on a, à part si nous le spécifions au moyen d'une petite suite de caractères au début du texte\n",
    "   - 19040, Takáts Sándor Szalai Barkóczy Krisztina 1671-1724 czímû könyvének ismertetése : ISO-8859-2 (latin2) encoding\n",
    "   - 41211, La comédie humaine volume I -- Scènes de la vie privée tome I : ISO-8859-1 (latin1) encoding\n",
    "   - 28049, Balady i romanse : UTF-8 encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, save the files on your computer.**\n",
    "\n",
    "Then, using `open(filename, encoding='XXX')`, read each file into a string under various declared encodings (XXX can be 'latin1', 'latin2' or 'utf8', or the `encoding` attribute can be missing).  Display a short fragment of the string to see if the result is correct.  You have 3x4 possibilities, so you may want to use list comprehensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='41211-8.txt' mode='r' encoding='utf8'>\n",
      "<_io.TextIOWrapper name='41211-8.txt' mode='r' encoding='latin1'>\n",
      "<_io.TextIOWrapper name='41211-8.txt' mode='r' encoding='latin2'>\n",
      "<_io.TextIOWrapper name='41211-8.txt' mode='r' encoding='cp1252'>\n",
      "<_io.TextIOWrapper name='19040-8.txt' mode='r' encoding='utf8'>\n",
      "<_io.TextIOWrapper name='19040-8.txt' mode='r' encoding='latin1'>\n",
      "<_io.TextIOWrapper name='19040-8.txt' mode='r' encoding='latin2'>\n",
      "<_io.TextIOWrapper name='19040-8.txt' mode='r' encoding='cp1252'>\n",
      "<_io.TextIOWrapper name='28049-0.txt' mode='r' encoding='utf8'>\n",
      "<_io.TextIOWrapper name='28049-0.txt' mode='r' encoding='latin1'>\n",
      "<_io.TextIOWrapper name='28049-0.txt' mode='r' encoding='latin2'>\n",
      "<_io.TextIOWrapper name='28049-0.txt' mode='r' encoding='cp1252'>\n",
      "The Project Gutenberg EBook of La com�die humaine volume I -- Sc�nes de la\n",
      "vie priv�e tome I, by Honor� de Balzac\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg \n",
      "The Project Gutenberg EBook of La comédie humaine volume I -- Scènes de la\n",
      "vie privée tome I, by Honoré de Balzac\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg \n",
      "The Project Gutenberg EBook of La comédie humaine volume I -- Scčnes de la\n",
      "vie privée tome I, by Honoré de Balzac\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg \n",
      "The Project Gutenberg EBook of La comédie humaine volume I -- Scènes de la\n",
      "vie privée tome I, by Honoré de Balzac\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg \n",
      "The Project Gutenberg EBook of Tak�ts S�ndor Szalai Bark�czy Krisztina\n",
      "1671-1724 cz�m� k�nyv�nek ismertet�se, by Angyal D�vid\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Projec\n",
      "The Project Gutenberg EBook of Takáts Sándor Szalai Barkóczy Krisztina\n",
      "1671-1724 czímû könyvének ismertetése, by Angyal Dávid\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Projec\n",
      "The Project Gutenberg EBook of Takáts Sándor Szalai Barkóczy Krisztina\n",
      "1671-1724 czímű könyvének ismertetése, by Angyal Dávid\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Projec\n",
      "The Project Gutenberg EBook of Takáts Sándor Szalai Barkóczy Krisztina\n",
      "1671-1724 czímû könyvének ismertetése, by Angyal Dávid\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Projec\n",
      "﻿The Project Gutenberg EBook of Balady i romanse, by Adam Mickiewicz\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at\n",
      "ï»¿The Project Gutenberg EBook of Balady i romanse, by Adam Mickiewicz\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online \n",
      "ďťżThe Project Gutenberg EBook of Balady i romanse, by Adam Mickiewicz\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online \n",
      "ï»¿The Project Gutenberg EBook of Balady i romanse, by Adam Mickiewicz\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online \n"
     ]
    }
   ],
   "source": [
    "book_fr = \"41211-8.txt\"\n",
    "book_hu = \"19040-8.txt\"\n",
    "book_pl = \"28049-0.txt\"\n",
    "books = [book_fr, book_hu, book_pl]\n",
    "# Chez moi l'encoding : '' ne fonctionnait pas je l'ai remplacé par None. None est égal à ne rien spécifier\n",
    "encodings = ['utf8', 'latin1', 'latin2', None]\n",
    "#Liste de tous les file directory (Je n'ai pas fais le read directement car je trouvais les informations des fd intéressantes)\n",
    "listFd = [open(x,encoding = encodings[i], errors=\"replace\") for x in books for i in range(0,len(encodings))]\n",
    "#Comme on peu le voir avec ce test si nous ne spécifions rien il prend l'encodage cp1252 (par défaut de windows)\n",
    "for i in range(0,len(listFd)):\n",
    "    print(listFd[i])\n",
    "# Affichage du début de chaque textes\n",
    "for i in range(0,len(listFd)):\n",
    "    print(listFd[i].read()[0:300])\n",
    "\n",
    "for i in range(0,len(listFd)):\n",
    "    listFd[i].close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you summarize your conclusion in the next table?  You should indicate for each file if the result obtained when reading it with each of the encodings is correct or not, and if not, please give (or describe) at least one character which is wrongly rendered.  Which of the combinations generates an error upon opening?  You can process those errors with the `errors='replace'` option.  What happens when you don't indicate an encoding at all?\n",
    "\n",
    "E = Error => problème encodage (Si on ne met pas : errors=\"replace\" => erreur à l'execution)\n",
    "\n",
    "N = Not Ok => problème d'encodage (mais pas besoin de mettre errors=\"replace\")\n",
    "\n",
    "O = Ok\n",
    "          \n",
    "| File (format)      | utf8  | latin1  | latin2  | none |\n",
    "| ------------------ | ----- | ------- | ------- | ---- |\n",
    "| book_fr (latin1)   | E     | O       |  N      | O    |\n",
    "| book_hu (latin2)   | E     | N       |  O      | N    |\n",
    "| book_pl (utf8)     | O     | N       |  N      | E    |\n",
    "\n",
    "\n",
    "\n",
    "(0,0) => Caractères accentué = carré avec points d'intérogation à l'intérieur\n",
    "\n",
    "(0,1) => Tout bon\n",
    "\n",
    "(0,2) => Remplace è par č\n",
    "\n",
    "(0,3) => Tout bon (j'imagine que le cp1252 contient les caractères du latin1)\n",
    "\n",
    "(1,0) => Caractères accentué = carré avec points d'intérogation à l'intérieur\n",
    "\n",
    "(1,1) => Certains accent sont modifié comme ű en û (et d'autre modification après les bytes commun à latin1 et latin2\n",
    "\n",
    "(1,2) => Tout bon\n",
    "\n",
    "(1,3) => Certains accent sont modifié comme ű en û (et d'autre modification après les bytes commun à latin1 et latin2\n",
    "\n",
    "(2,0) => Tout bon\n",
    "\n",
    "(2,1) =>  Certains caractères sont modifié comme ł en \"Å\" et on a aussi la chaine de caractères spécifiant l'UTF-8 que nous             avions vus : ï»¿\n",
    "\n",
    "(2,2) => Certains caractères sont modifié comme ł en \"Ĺ\"\n",
    "\n",
    "(2,3) => Certains caractères sont modifié comme ł en \"Å‚\" et on a aussi la chaine de caractères spécifiant l'UTF-8 que nous              avions vus : ï»¿\n",
    "\n",
    "Si nous ne spécifions rien l'encodage par défaut sera celui de l'OS => cp1252 pour moi (Windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please read correctly from file, then try to remove (by guessing) the initial and final parts of each file (which are not part of the real texts, e.g. PG header and licence) and **save each of them to a utf8 file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedWriter.close>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  codecs,os\n",
    "filename = 'finalString.txt'\n",
    "encodings2 = [ 'latin1', 'latin2', 'utf8']\n",
    "if os.path.exists(filename): \n",
    "    os.remove(filename)\n",
    "for i in range(0,len(encodings2)):\n",
    "    listFd2 = open(books[i], encoding= encodings2[i])\n",
    "    tmpText = listFd2.read()\n",
    "    debutText = tmpText.find(\"*** START OF THIS PROJECT GUTENBERG EBOOK\")\n",
    "    finText =   tmpText.find(\"*** END OF THIS PROJECT GUTENBERG EBOOK\")\n",
    "    fd = codecs.open(filename, 'a', 'utf8')\n",
    "    fd.write(''.join(tmpText[debutText + 75:finText]))\n",
    "    fd.close()\n",
    "    \n",
    "raw_fr_trim = codecs.open(filename, 'r', 'utf8').read()\n",
    "fd.close\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# the final string could be called raw_fr_trim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform sentence and word segmentation with several NLTK options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are three different options for **sentence segmentation.**\n",
    "\n",
    "*How many sentences do you find in each case?  Where do the differences come from?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10346\n"
     ]
    }
   ],
   "source": [
    "fr_sentences = nltk.sent_tokenize(raw_fr_trim)\n",
    "print(len(fr_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10406\n"
     ]
    }
   ],
   "source": [
    "fr_sentences2 = nltk.sent_tokenize(text=raw_fr_trim,language='french')\n",
    "print(len(fr_sentences2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10406\n"
     ]
    }
   ],
   "source": [
    "french_tokenizer = nltk.data.load(resource_url = 'tokenizers/punkt/french.pickle')\n",
    "fr_sentences3 = french_tokenizer.tokenize(raw_fr_trim)\n",
    "print(len(fr_sentences3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que la différence se situe entre le premier et les deux autres tokenizer. La différence majeur est que pour les deux dernier nous spécifions la langue qui doit être découpé. J'imagine que le tokenizer va découpé les phrases différement en fonction des langues(Dialogue, phrases non-normalisées)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now move to **tokenization** (splitting into words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Produced', 'by', 'Claudine', 'Corbasson', 'and', 'the', 'Online', 'Distributed', 'Proofreading', 'Team', 'at', 'http', ':', '//www.pgdp.net', '(', 'This', 'file', 'was', 'produced', 'from', 'images', 'generously', 'made', 'available', 'by', 'The', 'Internet', 'Archive/Canadian', 'Libraries', ')', 'Au', 'lecteur', 'Cette', 'version', 'numérisée', 'reproduit', ',', 'dans', 'son', 'intégralité', ',', 'la', 'version', 'originale', '.'], ['La', 'ponctuation', 'n', \"'\", 'a', 'pas', 'été', 'modifiée', 'hormis', 'quelques', 'corrections', 'mineures', '.'], [\"L'orthographe\", 'a', 'été', 'conservée', '.'], ['Seuls', 'quelques', 'mots', 'ont', 'été', 'modifiés', '.'], ['La', 'liste', 'des', 'modifications', 'se', 'trouve', 'à', 'la', 'fin', 'du', 'texte', '.'], ['OEUVRES', 'COMPLÈTES', 'DE', 'H', '.'], ['DE', 'BALZAC', 'LA', 'COMÉDIE', 'HUMAINE', 'PREMIER', 'VOLUME', 'PREMIÈRE', 'PARTIE', 'ÉTUDES', 'DE', 'MOEURS', 'PREMIER', 'LIVRE', 'PARIS.', '--', 'IMPRIMERIE', 'DE', 'E.', 'MARTINET', ',', 'RUE', 'MIGNON', ',', '2', '[', 'Illustration', ':', 'Balzac', ']', 'SCÈNES', 'DE', 'LA', 'VIE', 'PRIVÉE', 'TOME', '1', 'LA', 'MAISON', 'DU', 'CHAT-QUI-PELOTE', '--', 'LE', 'BAL', 'DE', 'SCEAUX', 'LA', 'BOURSE', '--', 'LA', 'VENDETTA', '--', 'MADAME', 'FIRMIANI', 'UNE', 'DOUBLE', 'FAMILLE', '--', 'LA', 'PAIX', 'DU', 'MÉNAGE', '--', 'LA', 'FAUSSE', 'MAITRESSE', 'ÉTUDE', 'DE', 'FEMME', '--', 'ALBERT', 'SAVARUS', 'PARIS', 'Veuve', 'ANDRE', 'HOUSSIAUX', ',', 'ÉDITEUR', 'HÉBERT', 'ET', 'Cie', ',', 'SUCCESSEURS', '7', ',', 'RUE', 'PERRONET', ',', '7', '1874', 'HONORÉ', 'DE', 'BALZAC', 'Balzac', 'naquit', 'à', 'Tours', 'le', '16', 'mai', '1799', ',', 'le', 'jour', 'de', 'la', 'fête', 'de', 'saint', 'Honoré', ',', 'dont', 'on', 'lui', 'donna', 'le', 'nom', ',', 'qui', 'parut', 'bien', 'sonnant', 'et', 'de', 'bon', 'augure', '.'], ['Le', 'petit', 'Honoré', 'ne', 'fut', 'pas', 'un', 'enfant', 'prodige', ';', 'il', \"n'annonça\", 'pas', 'prématurément', \"qu'il\", 'ferait', 'la', '_Comédie', 'humaine_', '.'], [\"C'était\", 'un', 'garçon', 'frais', ',', 'vermeil', ',', 'bien', 'portant', ',', 'joueur', ',', 'aux', 'yeux', 'brillants', 'et', 'doux', ',', 'mais', 'que', 'rien', 'ne', 'distinguait', 'des', 'autres', ',', 'du', 'moins', 'à', 'des', 'regards', 'peu', 'attentifs', '.'], ['A', 'sept', 'ans', ',', 'au', 'sortir', \"d'un\", 'externat', 'de', 'Tours', ',', 'on', 'le', 'mit', 'au', 'collége', 'de', 'Vendôme', ',', 'tenu', 'par', 'des', 'oratoriens', ',', 'où', 'il', 'passa', 'pour', 'un', 'élève', 'très-médiocre', '.']]\n"
     ]
    }
   ],
   "source": [
    "fr_words21 = [nltk.word_tokenize(sentence, language='french') for sentence in fr_sentences2]\n",
    "print(fr_words21[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Produced', 'by', 'Claudine', 'Corbasson', 'and', 'the', 'Online', 'Distributed', 'Proofreading', 'Team', 'at', 'http', ':', '//www.pgdp.net', '(', 'This', 'file', 'was', 'produced', 'from', 'images', 'generously', 'made', 'available', 'by', 'The', 'Internet', 'Archive/Canadian', 'Libraries', ')', 'Au', 'lecteur', 'Cette', 'version', 'numérisée', 'reproduit', ',', 'dans', 'son', 'intégralité', ',', 'la', 'version', 'originale', '.'], ['La', 'ponctuation', 'n', \"'\", 'a', 'pas', 'été', 'modifiée', 'hormis', 'quelques', 'corrections', 'mineures', '.'], [\"L'orthographe\", 'a', 'été', 'conservée', '.'], ['Seuls', 'quelques', 'mots', 'ont', 'été', 'modifiés', '.'], ['La', 'liste', 'des', 'modifications', 'se', 'trouve', 'à', 'la', 'fin', 'du', 'texte', '.'], ['OEUVRES', 'COMPLÈTES', 'DE', 'H', '.'], ['DE', 'BALZAC', 'LA', 'COMÉDIE', 'HUMAINE', 'PREMIER', 'VOLUME', 'PREMIÈRE', 'PARTIE', 'ÉTUDES', 'DE', 'MOEURS', 'PREMIER', 'LIVRE', 'PARIS.', '--', 'IMPRIMERIE', 'DE', 'E.', 'MARTINET', ',', 'RUE', 'MIGNON', ',', '2', '[', 'Illustration', ':', 'Balzac', ']', 'SCÈNES', 'DE', 'LA', 'VIE', 'PRIVÉE', 'TOME', '1', 'LA', 'MAISON', 'DU', 'CHAT-QUI-PELOTE', '--', 'LE', 'BAL', 'DE', 'SCEAUX', 'LA', 'BOURSE', '--', 'LA', 'VENDETTA', '--', 'MADAME', 'FIRMIANI', 'UNE', 'DOUBLE', 'FAMILLE', '--', 'LA', 'PAIX', 'DU', 'MÉNAGE', '--', 'LA', 'FAUSSE', 'MAITRESSE', 'ÉTUDE', 'DE', 'FEMME', '--', 'ALBERT', 'SAVARUS', 'PARIS', 'Veuve', 'ANDRE', 'HOUSSIAUX', ',', 'ÉDITEUR', 'HÉBERT', 'ET', 'Cie', ',', 'SUCCESSEURS', '7', ',', 'RUE', 'PERRONET', ',', '7', '1874', 'HONORÉ', 'DE', 'BALZAC', 'Balzac', 'naquit', 'à', 'Tours', 'le', '16', 'mai', '1799', ',', 'le', 'jour', 'de', 'la', 'fête', 'de', 'saint', 'Honoré', ',', 'dont', 'on', 'lui', 'donna', 'le', 'nom', ',', 'qui', 'parut', 'bien', 'sonnant', 'et', 'de', 'bon', 'augure', '.'], ['Le', 'petit', 'Honoré', 'ne', 'fut', 'pas', 'un', 'enfant', 'prodige', ';', 'il', \"n'annonça\", 'pas', 'prématurément', \"qu'il\", 'ferait', 'la', '_Comédie', 'humaine_', '.'], [\"C'était\", 'un', 'garçon', 'frais', ',', 'vermeil', ',', 'bien', 'portant', ',', 'joueur', ',', 'aux', 'yeux', 'brillants', 'et', 'doux', ',', 'mais', 'que', 'rien', 'ne', 'distinguait', 'des', 'autres', ',', 'du', 'moins', 'à', 'des', 'regards', 'peu', 'attentifs', '.'], ['A', 'sept', 'ans', ',', 'au', 'sortir', \"d'un\", 'externat', 'de', 'Tours', ',', 'on', 'le', 'mit', 'au', 'collége', 'de', 'Vendôme', ',', 'tenu', 'par', 'des', 'oratoriens', ',', 'où', 'il', 'passa', 'pour', 'un', 'élève', 'très-médiocre', '.']]\n"
     ]
    }
   ],
   "source": [
    "fr_words22 = [nltk.TreebankWordTokenizer().tokenize(sentence) for sentence in fr_sentences2]\n",
    "print(fr_words22[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the following tokenizer from NLTK better adapted to French?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Produced', 'by', 'Claudine', 'Corbasson', 'and', 'the', 'Online', 'Distributed', 'Proofreading', 'Team', 'at', 'http', '://', 'www', '.', 'pgdp', '.', 'net', '(', 'This', 'file', 'was', 'produced', 'from', 'images', 'generously', 'made', 'available', 'by', 'The', 'Internet', 'Archive', '/', 'Canadian', 'Libraries', ')', 'Au', 'lecteur', 'Cette', 'version', 'numérisée', 'reproduit', ',', 'dans', 'son', 'intégralité', ',', 'la', 'version', 'originale', '.'], ['La', 'ponctuation', 'n', \"'\", 'a', 'pas', 'été', 'modifiée', 'hormis', 'quelques', 'corrections', 'mineures', '.'], ['L', \"'\", 'orthographe', 'a', 'été', 'conservée', '.'], ['Seuls', 'quelques', 'mots', 'ont', 'été', 'modifiés', '.'], ['La', 'liste', 'des', 'modifications', 'se', 'trouve', 'à', 'la', 'fin', 'du', 'texte', '.'], ['OEUVRES', 'COMPLÈTES', 'DE', 'H', '.'], ['DE', 'BALZAC', 'LA', 'COMÉDIE', 'HUMAINE', 'PREMIER', 'VOLUME', 'PREMIÈRE', 'PARTIE', 'ÉTUDES', 'DE', 'MOEURS', 'PREMIER', 'LIVRE', 'PARIS', '.--', 'IMPRIMERIE', 'DE', 'E', '.', 'MARTINET', ',', 'RUE', 'MIGNON', ',', '2', '[', 'Illustration', ':', 'Balzac', ']', 'SCÈNES', 'DE', 'LA', 'VIE', 'PRIVÉE', 'TOME', '1', 'LA', 'MAISON', 'DU', 'CHAT', '-', 'QUI', '-', 'PELOTE', '--', 'LE', 'BAL', 'DE', 'SCEAUX', 'LA', 'BOURSE', '--', 'LA', 'VENDETTA', '--', 'MADAME', 'FIRMIANI', 'UNE', 'DOUBLE', 'FAMILLE', '--', 'LA', 'PAIX', 'DU', 'MÉNAGE', '--', 'LA', 'FAUSSE', 'MAITRESSE', 'ÉTUDE', 'DE', 'FEMME', '--', 'ALBERT', 'SAVARUS', 'PARIS', 'Veuve', 'ANDRE', 'HOUSSIAUX', ',', 'ÉDITEUR', 'HÉBERT', 'ET', 'Cie', ',', 'SUCCESSEURS', '7', ',', 'RUE', 'PERRONET', ',', '7', '1874', 'HONORÉ', 'DE', 'BALZAC', 'Balzac', 'naquit', 'à', 'Tours', 'le', '16', 'mai', '1799', ',', 'le', 'jour', 'de', 'la', 'fête', 'de', 'saint', 'Honoré', ',', 'dont', 'on', 'lui', 'donna', 'le', 'nom', ',', 'qui', 'parut', 'bien', 'sonnant', 'et', 'de', 'bon', 'augure', '.'], ['Le', 'petit', 'Honoré', 'ne', 'fut', 'pas', 'un', 'enfant', 'prodige', ';', 'il', 'n', \"'\", 'annonça', 'pas', 'prématurément', 'qu', \"'\", 'il', 'ferait', 'la', '_Comédie', 'humaine_', '.'], ['C', \"'\", 'était', 'un', 'garçon', 'frais', ',', 'vermeil', ',', 'bien', 'portant', ',', 'joueur', ',', 'aux', 'yeux', 'brillants', 'et', 'doux', ',', 'mais', 'que', 'rien', 'ne', 'distinguait', 'des', 'autres', ',', 'du', 'moins', 'à', 'des', 'regards', 'peu', 'attentifs', '.'], ['A', 'sept', 'ans', ',', 'au', 'sortir', 'd', \"'\", 'un', 'externat', 'de', 'Tours', ',', 'on', 'le', 'mit', 'au', 'collége', 'de', 'Vendôme', ',', 'tenu', 'par', 'des', 'oratoriens', ',', 'où', 'il', 'passa', 'pour', 'un', 'élève', 'très', '-', 'médiocre', '.']]\n"
     ]
    }
   ],
   "source": [
    "fr_words23 = [nltk.WordPunctTokenizer().tokenize(sentence) for sentence in fr_sentences2]\n",
    "print(fr_words23[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etant donné que le WordPunctTokenizer se base sur une regex toute simple : \"\\w+|[^\\w\\s]+.\". Je ne pense pas quelle soit nécessairement plus adapté au français. Surtout qu'il n'a pas été explicitement pensé pour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the result into a new file, in UTF8, one sentence per line, with tokens separated by whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_fr_saved_segmented = book_fr[:-3] + 'utf8.tok.txt'\n",
    "f = open(book_fr_saved_segmented, mode='a', encoding='utf8')\n",
    "for s in fr_words23:\n",
    "    for w in s:\n",
    "        f.write(w + ' ')\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional question\n",
    "Using regular expressions and some inspiration from the Web, can you write a better word tokenizer for French? \n",
    "\n",
    "For instance, a solution better adapted to French could be built based on: http://fabienpoulard.info/post/2008/03/05/Tokenisation-en-mots-avec-NLTK.  But the regular expression proposed there does not work: Quentin suggests to add in the first line after \\d+( the ?: characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework:** please send a PDF version of your notebook to `andrei.popescu-belis@heig-vd.ch` before Monday, March 4, 2019 at 23h59."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
